# -*- coding: utf-8 -*-
"""655 Machine Learning Group Project - IMDB Ratings

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aT7mXwdl3l7fc1FPzIKyiJUMhR2AgCUt

# IMDb Films and Series



*   Name: Name of the film/series
*   Data: Creation date
*   Rate: IMDB's Rate
*   Votes: Number of voters
*   Genre: Genres , Actions , Drama, Romance, etcâ€¦
*   Duration: Duration of the episode , film
*   Type: whether it's film or series
*   Certificate:
   *   TV-Y: Designed to be appropriate for all children
   *   TV-Y7: Suitable for ages 7 and up
   *   G: Suitable for General Audiences
   *   TV-G: Suitable for General Audiences
   *   PG: Parental Guidance suggested
   *   TV-PG: Parental Guidance suggested
   *   PG-13: Parents strongly cautioned. May be Inappropriate for ages 12 and under.
   *   TV-14: Parents strongly cautioned. May not be suitable for ages 14 and under.
   *   R: Restricted. May be inappropriate for ages 17 and under.
   *   TV-MA: For Mature Audiences. May not be suitable for ages 17 and under.
   *   NC-17: Inappropriate for ages 17 and under
*   Episodes: Number of Episodes only for series
*   Nudity, violence.. :How much does it have of these

# Load Libraries and Data
"""

#Import libraries
import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
import seaborn as sns
from io import StringIO
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV
from sklearn import metrics

# Load the csv file
imdb_url= 'https://drive.google.com/file/d/1In0RjoFruuh_rsfaqch31J9aRiLJ-9Ht/view?usp=sharing' #share link to data

file_id = imdb_url.split('/')[-2]
dwn_url='https://drive.google.com/uc?export=download&id=' + file_id
url = requests.get(dwn_url).text

csv_raw = StringIO(url)
imdb_df = pd.read_csv(csv_raw)

# Check out the file
# info, shape
imdb_df.info()
imdb_df.shape

#Check first few columns
imdb_df.head()

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# Check null values
imdb_df.isnull().sum()

"""# 1. Data Cleaning & Preparation
 Figure out how to clean genre (unpivot on excel maybe)
"""

# Replace no ratings with 0 and change attribute
imdb_df = imdb_df[imdb_df['Rate'] != 'No Rate']

#drop episode column
dropcolumns = ['Episodes']
imdb_df.drop(columns=dropcolumns, inplace=True)

#Clean rating, votes, duration, type columns
imdb_df['Votes'] = imdb_df['Votes'].str.replace(',','').replace('No Votes','0').replace('', '0')

imdb_df['Duration'].fillna(imdb_df['Duration'].median(), inplace=True)

imdbvotes = imdb_df[imdb_df['Votes']!=0]
imdbvotes['Votes'] = imdbvotes['Votes'].astype('int64')
imdb_df['Votes'] = imdb_df['Votes'].replace(0, imdbvotes['Votes'].median())
imdb_df['Votes'] = imdb_df['Votes'].astype('int64')

imdb_df['Certificate'] = imdb_df['Certificate'].fillna('Unrated')

imdb_df.head()

# Change attributes
imdb_df['Rate'] = imdb_df['Rate'].astype('float64')
imdb_df['Votes'] = imdb_df['Votes'].astype('int64')

imdb_df.info()

# Check unique values
imdb_df.nunique()

#dummy variable for type, certificate with binary
df_Type = {'Film': 1, 'Series':0}
imdb_df['Type'] = imdb_df['Type'].map(df_Type)
#ranked categorical for nudity, violence, profanity, alcohol, frightening
df_nudity={'No Rate': 1, 'Mild': 2, 'Moderate': 3, 'Severe': 4}
df_violence={'No Rate': 1, 'Mild': 2, 'Moderate': 3, 'Severe': 4}
df_profanity={'No Rate': 1, 'Mild': 2, 'Moderate': 3, 'Severe': 4}
df_alcohol={'No Rate': 1, 'Mild': 2, 'Moderate': 3, 'Severe': 4}
df_fright={'No Rate': 1, 'Mild': 2, 'Moderate': 3, 'Severe': 4}

imdb_df['Nudity'] = imdb_df['Nudity'].map(df_nudity)
imdb_df['Violence'] = imdb_df['Violence'].map(df_violence)
imdb_df['Profanity'] = imdb_df['Profanity'].map(df_profanity)
imdb_df['Alcohol'] = imdb_df['Alcohol'].map(df_alcohol)
imdb_df['Frightening'] = imdb_df['Frightening'].map(df_fright)

imdb_df['Nudity'].fillna(1, inplace=True)
imdb_df['Violence'].fillna(1, inplace=True)
imdb_df['Profanity'].fillna(1, inplace=True)
imdb_df['Alcohol'].fillna(1, inplace=True)
imdb_df['Frightening'].fillna(1, inplace=True)

# Join the list into a comma-separated string
imdb_df['Genre_str'] = imdb_df['Genre'].apply(lambda x: ','.join(x) if isinstance(x, list) else x)

# Remove extra spaces before one-hot encoding
imdb_df['Genre_str'] = imdb_df['Genre_str'].str.replace(', ', ',', regex=False)

# One-hot encode using str.get_dummies
genre_dummies = imdb_df['Genre_str'].str.get_dummies(sep=',')

# Optional: Add prefix
genre_dummies = genre_dummies.add_prefix('Genre_')

# Combine with original DataFrame
imdb_df = pd.concat([imdb_df, genre_dummies], axis=1)

# Drop intermediate column if needed
imdb_df.drop(columns=['Genre_str'], inplace=True)

imdb_df.info()

# One-hot encode using str.get_dummies
Certificate_dummies = imdb_df['Certificate'].str.get_dummies(sep=',')

# Optional: Add prefix
Certificate_dummies = Certificate_dummies.add_prefix('Certificate_')

# Combine with original DataFrame
imdb_df = pd.concat([imdb_df, Certificate_dummies], axis=1)

# Only convert the one-hot encoded columns to integers
one_hot_cols = [col for col in imdb_df.columns if col.startswith('Certificate_')]
imdb_df[one_hot_cols] = imdb_df[one_hot_cols].astype(int)

imdb_df.info()

imdb_df.head()

imdb_df.info()

# Drop name as unique identifier
imdb_df.drop(columns=['Name'], inplace=True)

"""# 2. Exploratory Data Analysis"""

# Descriptive statistics
imdb_df.describe()

# Graphs/charts (histograms, bar, scatter, box plots)

# Distribution of Duration
plt.figure(figsize=(10, 6))
imdb_df['Duration'].plot.hist()
plt.title('Distribution of Duration')
plt.xlabel('Duration')
plt.ylabel('Count')
plt.show()

##Date
plt.figure(figsize=(10, 6))
imdb_df['Date'].plot.hist()
plt.title('Year of Film')
plt.xlabel('Year')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
imdb_df['Votes'].plot.hist()
plt.title('Distribution of Votes')
plt.xlabel('Vote')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
imdb_df['Nudity'].plot.hist()
plt.title('Distribution of Nudity')
plt.xlabel('Nudity')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
imdb_df['Violence'].plot.hist()
plt.title('Distribution of Violence')
plt.xlabel('Violence')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
imdb_df['Profanity'].plot.hist()
plt.title('Distribution of Profanity')
plt.xlabel('Profanity')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
imdb_df['Alcohol'].plot.hist()
plt.title('Distribution of Alcohol')
plt.xlabel('Alcohol')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 6))
imdb_df['Frightening'].plot.hist()
plt.title('Distribution of Frightening')
plt.xlabel('Frightening')
plt.ylabel('Count')
plt.show()
# Plot target variable

## Categorical Data

##Genres
plt.show()
genre_col = [col for col in imdb_df.columns if col.startswith('Genre_')]
category_counts = imdb_df[genre_col].sum().sort_values(ascending=False)
category_counts.plot(kind='bar', color='skyblue')
plt.xlabel('Genre')
plt.ylabel('Count')
plt.title('Movie Genres')

##Certificate
plt.show()
# Access one-hot encoded certificate columns instead of original 'Certificate' column
certificate_cols = [col for col in imdb_df.columns if col.startswith('Certificate_')]
category_counts = imdb_df[certificate_cols].sum().sort_values(ascending=False)
category_counts.plot(kind='bar', color='skyblue')
plt.xlabel('Certificate')
plt.ylabel('Count')
plt.title('Movie Certificate')

##Type
plt.show()
category_counts = imdb_df['Type'].value_counts()
category_counts.plot(kind='bar', color='skyblue')
plt.xlabel('Type')
plt.ylabel('Count')
plt.title('Film vs Series')
xticks_locations = plt.xticks()[0]
plt.xticks(xticks_locations, ['Film', 'Series'])

#Plot output variable
plt.figure(figsize=(10, 6))
imdb_df['Rate'].plot.hist()
plt.title('Distribution of Rate')
plt.xlabel('Rate')
plt.ylabel('Count')
plt.show()

# Bivariate analysis of ratings of other variables

#Rating x certificate

plt.figure(figsize=(10, 6))
sns.boxplot(x='Certificate', y='Rate', data=imdb_df)

plt.title('Certificate Ratings')
plt.xlabel('Certificate')
plt.ylabel('Ratings')
plt.xticks(rotation=90) # Rotate x-axis labels for better readability
plt.grid(axis='y') # Specify y-axis for the grid
plt.show()

# Rating x Frightening
plt.figure(figsize=(10, 6))
sns.boxplot(x='Frightening', y='Rate', data=imdb_df)

plt.title('Frightening Ratings')
plt.xlabel('Data Sets')
plt.ylabel('Ratings')
plt.show()

# Scatterplot of Date x Rating
plt.figure(figsize=(10, 6))
plt.scatter(imdb_df['Date'], imdb_df['Rate'], alpha=0.5)
plt.title('Date vs. Rating')
plt.xlabel('Date')
plt.ylabel('Rating')

# Filter out rows with outliers
filtered_df = imdb_df[(imdb_df['Duration'] >= 0) & (imdb_df['Duration'] <= 400)]

# Scatterplot of Duration x Rating
plt.figure(figsize=(10, 6))
plt.scatter(filtered_df['Duration'], filtered_df['Rate'], alpha=0.5)
plt.title('Duration vs. Rating (Outliers Removed)')
plt.xlabel('Duration')
plt.ylabel('Rating')
plt.show()

#Scatterplot of Votes x Rating
plt.figure(figsize=(10, 6))
plt.scatter(imdb_df['Votes'], imdb_df['Rate'], alpha=0.5)
plt.title('Votes vs. Rating')
plt.xlabel('Votes')
plt.ylabel('Rating')

# Correlation matrix, heatmap, pairwise plots
corr_matrix = imdb_df[['Date','Rate','Votes','Duration','Type','Nudity','Violence','Profanity','Alcohol','Frightening']].corr()

# Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix')
plt.show()

# Multicollinearity

# Drop Violence due to multicollinearity
imdb_df.drop(columns=['Violence'], inplace=True)

# Drop Genre and Certificate original columns
imdb_df.drop(columns=['Genre', 'Certificate'], inplace=True)

imdb_df.shape

"""#3. Data Partitioning"""

# Split, train, test
X = imdb_df.drop(columns=['Rate'])
y = imdb_df['Rate']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.4, random_state=1)

X_train.info()

X_val.info()

X_test.info()

"""# 4. Building Models"""

#Performance Metrics

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluate_regression_model(model, X_train, X_test, y_train, y_test):
    """
    Evaluates the performance of a regression model on training and testing data.

    Parameters:
    - model: The regression model to evaluate.
    - X_train: Training feature data.
    - X_test: Testing feature data.
    - y_train: Training target data.
    - y_test: Testing target data.

    Returns:
    - DataFrame with performance metrics (MSE, MAE, RMSE, and R-squared) for train and test sets.
    """

    # Predictions on training data
    y_train_pred = model.predict(X_train)

    # Predictions on testing data
    y_test_pred = model.predict(X_test)

    # Calculate metrics for both train and test data
    metrics = {
        "Data": ["Train", "Test"],
        "MSE": [
            mean_squared_error(y_train, y_train_pred),
            mean_squared_error(y_test, y_test_pred),
        ],
        "MAE": [
            mean_absolute_error(y_train, y_train_pred),
            mean_absolute_error(y_test, y_test_pred),
        ],
        "RMSE": [
            np.sqrt(mean_squared_error(y_train, y_train_pred)),
            np.sqrt(mean_squared_error(y_test, y_test_pred)),
        ],
        "R-squared": [
            r2_score(y_train, y_train_pred),
            r2_score(y_test, y_test_pred),
        ],
    }

    # Create a DataFrame to display the metrics
    performance_df = pd.DataFrame(metrics)

    # Print the performance DataFrame
    return performance_df

"""## Linear Regression Model"""

#Build a Linear Regression Model
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

#Make Predictions on validation
y_pred_val = lin_reg.predict(X_val)

# Checking model performance on validation
evaluate_regression_model(lin_reg, X_train, X_val, y_train, y_val)

# Make predictions on test
y_pred_test = lin_reg.predict(X_test)

# Evaluate model performance on test
evaluate_regression_model(lin_reg, X_train, X_test, y_train, y_test)

#Feature Importance
coefficients = lin_reg.coef_
# Reshape coefficients to be 1-dimensional
coefficients = coefficients.flatten()  # Or coefficients.reshape(-1)
importance_lin_reg = pd.DataFrame({'Feature': X.columns, 'Importance': coefficients})
importance_lin_reg = importance_lin_reg.sort_values('Importance', ascending=False)
print(importance_lin_reg)

plt.figure(figsize=(10, 6))
plt.barh(importance_lin_reg['Feature'], importance_lin_reg['Importance'])
plt.gca().invert_yaxis()
plt.xlabel('Importance')
plt.title('Feature Importance from Linear Regression')
plt.show()

"""## K Nearest Neighbors"""

# Scale predictor variables
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)
X_temp_scaled = scaler.transform(X_temp)

knn = KNeighborsRegressor()

# Dictionary to store average training and validation MSE for each k
knn_many_split = {}

# Loop through k values
for k in range(1, 15):
    train_error = []
    test_error = []

    for i in range(30):  # Repeat splitting and training for stability
        X_val_new, X_test_new, y_val_new, y_test_new = train_test_split(X_temp_scaled, y_temp, test_size=0.4, random_state=1)

        # Initialize and train the KNN regressor
        knn = KNeighborsRegressor(n_neighbors=k)
        knn.fit(X_train_scaled, y_train)

        # Predict and calculate MSE
        y_train_pred = knn.predict(X_train_scaled)
        y_val_pred = knn.predict(X_val_new)

        train_error.append(mean_squared_error(y_train, y_train_pred))
        test_error.append(mean_squared_error(y_val_new, y_val_pred))

    # Store the average training and validation MSE for current k
    knn_many_split[k] = [sum(train_error)/len(train_error), sum(test_error)/len(test_error)]

# Prepare lists for plotting
kltrain = list(knn_many_split.keys())
vltrain = [v[0] for v in knn_many_split.values()]  # Training MSE
vltest = [v[1] for v in knn_many_split.values()]   # Validation MSE

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(kltrain, vltest, label='Validation MSE', marker='o')
plt.plot(kltrain, vltrain, label='Training MSE', marker='o')
plt.title('MSE vs. Number of Neighbors (k)')
plt.xlabel('Number of Neighbors (k)')
plt.ylabel('Mean Squared Error')
plt.grid(True)
plt.legend(title='Dataset')
plt.show()

knn = KNeighborsRegressor(n_neighbors=7)

#fitting data to the KNN model
knn.fit(X_train_scaled, y_train)

#checking the performance of knn model
y_pred_train_knn = knn.predict(X_train_scaled)
y_pred_val_knn = knn.predict(X_val_scaled)

#Evaluate metrics of knn model
mse_train_knn = mean_squared_error(y_train, y_pred_train_knn)
mse_val_knn = mean_squared_error(y_val, y_pred_val_knn)

print(f"MSE on Training Data (KNN): {mse_train_knn}")
print(f"MSE on Test Data (KNN): {mse_val_knn}")
print(f"R2 on Training Data (KNN): {r2_score(y_train, y_pred_train_knn)}")
print(f"R2 on Test Data (KNN): {r2_score(y_val, y_pred_val_knn)}")

evaluate_regression_model(knn, X_train_scaled, X_val_scaled, y_train, y_val)

knn = KNeighborsRegressor(n_neighbors=7)

#fitting data to the KNN model
knn.fit(X_train_scaled, y_train)

#checking the performance of knn model
y_pred_train_knn = knn.predict(X_train_scaled)
y_pred_test_knn = knn.predict(X_test_scaled)

#Evaluate metrics of knn model
mse_train_knn = mean_squared_error(y_train, y_pred_train_knn)
mse_test_knn = mean_squared_error(y_test, y_pred_test_knn)

print(f"MSE on Training Data (KNN): {mse_train_knn}")
print(f"MSE on Test Data (KNN): {mse_test_knn}")
print(f"R2 on Training Data (KNN): {r2_score(y_train, y_pred_train_knn)}")
print(f"R2 on Test Data (KNN): {r2_score(y_test, y_pred_test_knn)}")

evaluate_regression_model(knn, X_train_scaled, X_test_scaled, y_train, y_test)

from sklearn.inspection import permutation_importance

# Evaluate importance
results = permutation_importance(knn, X_val_scaled, y_val, n_repeats=30, random_state=42)

# Display importances
importance_knn = pd.DataFrame({
    'Feature': X_test.columns,
    'Importance': results.importances_mean
}).sort_values(by='Importance', ascending=False)

print(importance_knn)

#Plot
plt.figure(figsize=(10, 6))
plt.barh(importance_knn['Feature'], importance_knn['Importance'])
plt.gca().invert_yaxis()
plt.xlabel('Importance')
plt.title('Feature Importance from KNearest Neighbors')
plt.show()

"""## Decision Tree Model"""

from sklearn.tree import DecisionTreeRegressor
decision_tree = DecisionTreeRegressor(random_state=42)
decision_tree.fit(X_train, y_train)

# Checking Decision Tree model performance on validation
params = {'max_depth': [3, 5, 10, None],
          'min_samples_split': [2, 5, 10]}

evaluate_regression_model(decision_tree, X_train, X_val, y_train, y_val)

grid = GridSearchCV(decision_tree, params, cv=3)
grid.fit(X_train, y_train)  # Combine X_train + X_val if needed
test_preds = grid.predict(X_test)

# Checking Decision Tree model performance on test
evaluate_regression_model(grid, X_train, X_test, y_train, y_test)

# Get feature importances
importances_dt = decision_tree.feature_importances_
features = X_train.columns

# Create DataFrame and sort
importance_dt = pd.DataFrame({
    'Feature': features,
    'Importance': importances_dt
}).sort_values(by='Importance', ascending=False)

# Display table
print(importance_dt)

# Optional: Plot
plt.figure(figsize=(10, 6))
plt.barh(importance_dt['Feature'], importance_dt['Importance'])
plt.gca().invert_yaxis()
plt.xlabel('Importance')
plt.title('Feature Importance from Decision Tree')
plt.show()

"""## Random Forest Model"""

#Random Forest Model
from sklearn.ensemble import RandomForestRegressor
rand_forest = RandomForestRegressor(n_estimators=50, random_state=42)
rand_forest.fit(X_train, y_train)

# Checking model performance
evaluate_regression_model(rand_forest, X_train, X_val, y_train, y_val)

from sklearn.model_selection import GridSearchCV

rf_estimator_tuned = RandomForestRegressor(random_state=42)

# Grid of parameters to choose from
params_rf = {
    "n_estimators": [50, 100, 200, 300],
    "max_depth": [None, 10, 20, 30],
    "min_samples_split": [2, 5, 10],
}

# Use 'neg_mean_squared_error' or another valid scoring metric
grid_obj = GridSearchCV(rf_estimator_tuned, params_rf, scoring='neg_mean_squared_error', cv=5)
grid_obj = grid_obj.fit(X_train, y_train)

# Set the clf to the best combination of parameters
rf_estimator_tuned = grid_obj.best_estimator_

rf_estimator_tuned.fit(X_train, y_train)

evaluate_regression_model(rf_estimator_tuned, X_train, X_test, y_train, y_test)

# Get importances
importances_rf = rf_estimator_tuned.feature_importances_
features = X_train.columns

# Create DataFrame
importance_rf = pd.DataFrame({
    'Feature': features,
    'Importance': importances_rf
}).sort_values(by='Importance', ascending=False)

# Display
print(importance_rf)

# Plot
plt.figure(figsize=(10, 6))
plt.barh(importance_rf['Feature'], importance_rf['Importance'])
plt.gca().invert_yaxis()
plt.xlabel('Importance')
plt.title('Feature Importance from Random Forest')
plt.tight_layout()
plt.show()